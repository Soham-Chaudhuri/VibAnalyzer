{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-29T14:01:58.303574Z",
     "iopub.status.busy": "2024-11-29T14:01:58.299596Z",
     "iopub.status.idle": "2024-11-29T14:02:00.197947Z",
     "shell.execute_reply": "2024-11-29T14:02:00.197198Z",
     "shell.execute_reply.started": "2024-11-29T14:01:58.303511Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:41:32.465999Z",
     "iopub.status.busy": "2024-12-01T10:41:32.464898Z",
     "iopub.status.idle": "2024-12-01T10:42:19.188614Z",
     "shell.execute_reply": "2024-12-01T10:42:19.187874Z",
     "shell.execute_reply.started": "2024-12-01T10:41:32.465952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Paths to folders and their corresponding output values\n",
    "folder_mappings = {\n",
    "    '/kaggle/input/im-fault/0.5mm': 0,\n",
    "    '/kaggle/input/im-fault/1.0mm': 0,\n",
    "    '/kaggle/input/im-fault/1.5mm': 1,\n",
    "    '/kaggle/input/im-fault/2.0mm': 1,\n",
    "    '/kaggle/input/im-fault/normal': 0\n",
    "}\n",
    "\n",
    "# Parameters for downsampling\n",
    "sample_fraction = 0.1  # Retain 10% of rows from each file\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Process each folder and its CSV files\n",
    "for folder, output_value in folder_mappings.items():\n",
    "    csv_files = glob.glob(os.path.join(folder, '*.csv'))\n",
    "    \n",
    "    for file in csv_files:\n",
    "        # Read the file without assuming headers\n",
    "        df = pd.read_csv(file, header=None)\n",
    "        \n",
    "        # Downsample the file\n",
    "        downsampled_df = df.sample(frac=sample_fraction, random_state=42)\n",
    "        \n",
    "        # Add the output column\n",
    "        downsampled_df['output'] = output_value\n",
    "        \n",
    "        # Append the modified DataFrame to the list\n",
    "        dataframes.append(downsampled_df)\n",
    "\n",
    "# Concatenate all the downsampled DataFrames\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Add custom header columns\n",
    "merged_df.columns = [\n",
    "    'rotation freq', 'uh_ax_vib', 'uh_rd_vib', 'uh_tg_vib',\n",
    "    'oh_ax_vib', 'oh_rd_vib', 'oh_tg_vib', 'microphone', 'output'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:48:03.798568Z",
     "iopub.status.busy": "2024-12-01T10:48:03.798198Z",
     "iopub.status.idle": "2024-12-01T10:48:06.384469Z",
     "shell.execute_reply": "2024-12-01T10:48:06.383576Z",
     "shell.execute_reply.started": "2024-12-01T10:48:03.798538Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rotation freq_fft  uh_ax_vib_fft  uh_rd_vib_fft  uh_tg_vib_fft  \\\n",
      "0        1004.343013   68804.753690     292.980677    3158.538155   \n",
      "1        3269.751824   13532.195716     460.327254     985.479991   \n",
      "2        6881.740197    4501.487223      28.316261    1064.720351   \n",
      "3        5881.330951    1959.230291    1579.416536     433.786726   \n",
      "4        4218.824797    1956.575544     687.398252     872.787272   \n",
      "\n",
      "   oh_ax_vib_fft  oh_rd_vib_fft  oh_tg_vib_fft  microphone_fft  output  \n",
      "0   71700.382050   18791.174820   66569.925957    80609.907232       0  \n",
      "1    6845.204759      78.532673   30839.765520     3903.642134       0  \n",
      "2   14313.868282    1017.411608   15442.677752      446.887554       0  \n",
      "3    7180.536977     165.598974    2747.267940      516.773715       0  \n",
      "4   11647.841365     280.065261   23563.294336      867.180183       0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.fft import fft\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Function to apply FFT to a specific column in the DataFrame\n",
    "def apply_fft_scipy(df, column_name):\n",
    "    # Perform FFT on the column data\n",
    "    fft_values = fft(df[column_name])\n",
    "    # Return only the magnitude of the FFT result\n",
    "    return np.abs(fft_values)\n",
    "\n",
    "# Columns to apply FFT (excluding the 'output' column)\n",
    "data_columns = [\n",
    "    'rotation freq', 'uh_ax_vib', 'uh_rd_vib', 'uh_tg_vib',\n",
    "    'oh_ax_vib', 'oh_rd_vib', 'oh_tg_vib', 'microphone'\n",
    "]\n",
    "\n",
    "# Create an empty dictionary to store FFT results\n",
    "fft_data = {}\n",
    "\n",
    "# Apply FFT to each column and store in the dictionary\n",
    "for col in data_columns:\n",
    "    fft_data[f'{col}_fft'] = apply_fft_scipy(merged_df, col)[:len(merged_df)]\n",
    "\n",
    "# Convert the dictionary to a new DataFrame\n",
    "fft_df = pd.DataFrame(fft_data)\n",
    "\n",
    "# Copy the 'output' column to the new DataFrame\n",
    "fft_df['output'] = merged_df['output']\n",
    "\n",
    "# Check the FFT DataFrame\n",
    "print(fft_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-01T10:48:23.247687Z",
     "iopub.status.busy": "2024-12-01T10:48:23.246996Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.6014\n",
      "\n",
      "Model: Logistic Regression with Accuracy: 0.6014\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Print accuracy\n",
    "    print(f'{model_name} Accuracy: {score:.4f}')\n",
    "    \n",
    "    # Print classification report\n",
    "    print(f\"Classification Report for {model_name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    # Update the best model if necessary\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model_name\n",
    "\n",
    "print(f'\\nBest Model: {best_model} with Accuracy: {best_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6093956,
     "sourceId": 9916512,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
